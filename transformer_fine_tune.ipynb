{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "062f17b0-776c-4db0-8312-a65015ce4351",
   "metadata": {},
   "source": [
    "# Fine-tuning a Machine Translation Transformer Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13deda50-fef1-4806-bec4-8ffe43e12a69",
   "metadata": {},
   "source": [
    "The objective of the project is to fine-tune a pretrained Helsinki-NLP/opus-mt-en-de Transformer model with the Europarl English-German parallel corpus.\n",
    "See the links to datasets and tutorials followed below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92281b4b-6648-4833-b469-fac73634f48a",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed9bb6b-e3cb-4367-a515-66102ce51601",
   "metadata": {},
   "source": [
    "Importing libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2ca216-9025-47b6-9818-84d660f26d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer, AutoTokenizer, DataCollatorForSeq2Seq\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954f6263-4de3-4026-a73d-f816cb35088c",
   "metadata": {},
   "source": [
    "Defining English as a source language and German as a target language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d00410-2303-4a6b-b657-f89ef94773d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = \"en\"\n",
    "TG = \"de\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "3e1a2e8e-8b31-48ab-b677-ca9e1bbf6b7a",
   "metadata": {},
   "source": [
    "Loading dataset with 2000 English-German sentence pairs from a csv file and splitting data into a train (85%) and a test set (15%):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a6a2fa-03ec-4dd0-a2cf-1f48348b622b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_data = load_dataset(\"csv\", data_files= \"de-en/train_set.csv\")\n",
    "parallel_data = parallel_data[\"train\"].train_test_split(test_size=0.15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dc1418-4a76-4878-a83c-ceeb4fe2929b",
   "metadata": {},
   "source": [
    "Dataset preprocessing (tokenization) in order to use the produced tokenized sentences as inputs for the transformer model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b02ae0-b994-4529-9024-912fe83d467a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = [example for example in examples[SRC]]\n",
    "    targets = [example for example in examples[TG]]\n",
    "    model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True)\n",
    "    return model_inputs\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\")\n",
    "tokenized_inputs = parallel_data.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b79df9-fff4-447d-9293-2a018712d29f",
   "metadata": {},
   "source": [
    "Loading model and creating a data collator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c72b3e7-2faf-44a8-88ae-f19bede2f3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-de\")\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f5b33c-125d-4161-bd3b-68d0dc62e929",
   "metadata": {},
   "source": [
    "Functions for model evaluation with SacreBLEU metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9975ccbd-63ed-46be-85c1-2988aed17596",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"sacrebleu\")\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78b6d24-f430-4bf0-bab4-73c65f11f62d",
   "metadata": {},
   "source": [
    "Writing training arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef2eb8f-dde9-4f06-bab4-876270f5f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"europarl-de-en\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=0.00002,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=5,\n",
    "    predict_with_generate=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "#If the model is meant to be uploaded, set \"push_to_hub\" to True."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da44d7f-9110-4db0-8a99-a00e6e01b83f",
   "metadata": {},
   "source": [
    "Creating a trainer object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5518915c-b0ef-4e37-912b-7be1841574c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_inputs[\"train\"],\n",
    "    eval_dataset=tokenized_inputs[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c91e487f-394c-4459-9d4c-e0dd2b1a0fba",
   "metadata": {},
   "source": [
    "Model training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c906cfb6-193b-4089-8cb5-c2cf5831d426",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcee110-a715-430a-b042-1a4116926c68",
   "metadata": {},
   "source": [
    "The model was pushed to the hub with the following code: trainer.push_to_hub()\n",
    "\n",
    "Let's test the model.\n",
    "Downloading the fine-tuned model from the hub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95737835-16cb-4688-a3af-77284b2d7a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "europarl_model = AutoModelForSeq2SeqLM.from_pretrained(\"marsim0/europarl-de-en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280c32ad-af6a-42aa-8639-32d9273f8454",
   "metadata": {},
   "source": [
    "Reading 20 a few new English sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8d8ff0-e46e-4b59-b2e7-09773735d614",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"de-en/test.en\", \"r\", encoding=\"windows-1252\") as file:\n",
    "    eng_sents = file.readlines()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dc0344-cd9f-46a8-b359-bc6b08ff93ba",
   "metadata": {},
   "source": [
    "Generating a dictionary with translations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e79d21b-c2bd-42a5-80d4-86988a731d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"marsim0/europarl-de-en\")\n",
    "    translations = {}\n",
    "    for sent in text:\n",
    "        inputs = tokenizer(sent, return_tensors=\"pt\").input_ids\n",
    "        outputs = europarl_model.generate(inputs, max_new_tokens=40, do_sample=True, top_k=30, top_p=0.95)\n",
    "        decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        translations[sent] = decoded\n",
    "    return translations\n",
    "\n",
    "transdict = translate(eng_sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbdc976-1853-403c-88c4-5450caa183b7",
   "metadata": {},
   "source": [
    "Run to see the output of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2affd9f-11c6-490e-82e1-f901f2624541",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in transdict:\n",
    "    print(f\"EN: {sent}DE: {transdict[sent]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41294472-6442-4404-808e-27c1c048326a",
   "metadata": {},
   "source": [
    "You can also see the previously generated output of this model in the \"europarl-de-en_output\" file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6126ebeb-0808-47ee-b876-8ce33c339327",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ce21e8-dc6a-40aa-b703-a43a09adceff",
   "metadata": {},
   "source": [
    "The comparison of both models demonstrates that the fine tuned model had a slightly better performance, even though fine tuning was performed on a small dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f186769-dba6-4d67-b0d2-f79ea105d9a4",
   "metadata": {},
   "source": [
    "| Model | Evaluation Loss | Sacrebleu Score |\n",
    "| --- | --- | --- |\n",
    "| Original | 1.506978 | 23.8212 |\n",
    "| Fine Tuned | 1.424564 | 24.8548 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddeb5f1-9e72-4037-bc89-ccec1881de5a",
   "metadata": {},
   "source": [
    "## Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f2df05-15e6-49d2-b938-e2e07be47757",
   "metadata": {},
   "source": [
    "### Hugging Face Tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a36f9ef-8f15-47a8-b9b3-ecc5e22b6a1b",
   "metadata": {},
   "source": [
    "[Fine-tune a pretrained model](https://huggingface.co/docs/transformers/training)\n",
    "\n",
    "[Translation](https://huggingface.co/docs/transformers/tasks/translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39530f67-d22b-4def-9ec3-85897793631e",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544c00e4-7ef6-4b85-8dee-fbf83a481716",
   "metadata": {},
   "source": [
    "[Europarl](https://statmt.org/europarl/) English-German Parallel corpus from (taken from the [NAACL 2006 WORKSHOP](https://statmt.org/wmt06/shared-task/))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
